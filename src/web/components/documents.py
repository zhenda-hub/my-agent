"""æ–‡æ¡£ç®¡ç†ç»„ä»¶"""
import streamlit as st
import tempfile
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from src.vector_store import VectorStore


def split_text(text: str, chunk_size: int = 500, overlap: int = 50) -> list[str]:
    """å°†æ–‡æœ¬åˆ‡åˆ†æˆå°å—"""
    if len(text) <= chunk_size:
        return [text]

    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size

        # å°è¯•åœ¨å¥å·ã€æ¢è¡Œç¬¦ç­‰ä½ç½®åˆ‡åˆ†
        if end < len(text):
            period_pos = text.rfind("ã€‚", start, end)
            exclamation_pos = text.rfind("ï¼", start, end)
            question_pos = text.rfind("ï¼Ÿ", start, end)
            newline_pos = text.rfind("\n", start, end)

            best_pos = max(period_pos, exclamation_pos, question_pos, newline_pos)
            if best_pos > start + chunk_size // 2:
                end = best_pos + 1

        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)

        start = end - overlap if end < len(text) else end

    return chunks


def render_document_panel(vector_store: "VectorStore") -> None:
    """æ¸²æŸ“æ–‡æ¡£ä¸Šä¼ é¢æ¿

    Args:
        vector_store: å‘é‡å­˜å‚¨å®ä¾‹
    """
    with st.expander("ğŸ“„ ä¸Šä¼ æ–‡æ¡£", expanded=True):
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            accept_multiple_files=True,
            type=['pdf', 'docx', 'txt', 'md', 'epub'],
            help="æ”¯æŒï¼šPDF, DOCX, TXT, MD, EPUB"
        )

        if uploaded_files and st.button("ä¸Šä¼ ", type="primary", use_container_width=True):
            with st.status("æ­£åœ¨å¤„ç†...", expanded=True) as status:
                from src.loaders import get_loader
                from src.loaders.base import Document

                total = len(uploaded_files)
                for i, file in enumerate(uploaded_files):
                    status.update(label=f"å¤„ç† {file.name} ({i+1}/{total})")

                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.name).suffix) as f:
                        f.write(file.getvalue())
                        temp_path = f.name

                    try:
                        path = Path(temp_path)

                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        if vector_store.source_exists(str(path)):
                            st.info(f"â­ï¸ {file.name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                            continue

                        # åŠ è½½æ–‡æ¡£
                        loader = get_loader(str(path))
                        documents = loader.load(str(path))

                        # åˆ‡åˆ†æ–‡æ¡£
                        chunked_docs = []
                        for doc in documents:
                            chunks = split_text(doc.content)
                            for j, chunk in enumerate(chunks):
                                chunked_doc = Document(
                                    content=chunk,
                                    metadata={
                                        **doc.metadata,
                                        "chunk_index": j,
                                        "total_chunks": len(chunks),
                                    },
                                    source=doc.source,
                                )
                                chunked_docs.append(chunked_doc)

                        # æ¸…é™¤æ—§æ•°æ®
                        vector_store.delete_by_source(str(path))

                        # å­˜å‚¨åˆ°å‘é‡åº“
                        vector_store.add_documents(chunked_docs)
                        st.success(f"âœ… {file.name}: {len(chunked_docs)} ä¸ªå—")

                    except Exception as e:
                        st.error(f"âŒ {file.name}: {e}")

                status.update(label="å®Œæˆï¼", state="complete")
                st.session_state.documents_loaded = True
                st.rerun()


def render_web_scraping(vector_store: "VectorStore") -> None:
    """æ¸²æŸ“ç½‘é¡µæŠ“å–é¢æ¿

    Args:
        vector_store: å‘é‡å­˜å‚¨å®ä¾‹
    """
    with st.expander("ğŸ”— ç½‘é¡µæŠ“å–"):
        url = st.text_input("ç½‘é¡µ URL", placeholder="https://example.com", key="web_url")

        if st.button("æŠ“å–", use_container_width=True, key="scrape_btn"):
            if url and url.strip():
                url = url.strip()

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if vector_store.source_exists(url):
                    st.warning(f"â­ï¸ URL å·²å­˜åœ¨: {url}")
                    return

                with st.spinner("æ­£åœ¨æŠ“å–..."):
                    try:
                        from src.loaders.web_loader import WebLoader
                        from src.loaders.base import Document

                        # æŠ“å–ç½‘é¡µ
                        loader = WebLoader()
                        documents = loader.load(url)

                        # åˆ‡åˆ†æ–‡æ¡£
                        chunked_docs = []
                        for doc in documents:
                            chunks = split_text(doc.content)
                            for i, chunk in enumerate(chunks):
                                chunked_doc = Document(
                                    content=chunk,
                                    metadata={
                                        **doc.metadata,
                                        "chunk_index": i,
                                        "total_chunks": len(chunks),
                                    },
                                    source=doc.source,
                                )
                                chunked_docs.append(chunked_doc)

                        # å­˜å‚¨åˆ°å‘é‡åº“
                        vector_store.add_documents(chunked_docs)

                        st.success(f"âœ… æˆåŠŸæŠ“å–ï¼š{url}\nğŸ“Š å…± {len(chunked_docs)} ä¸ªæ–‡æ¡£å—")
                        st.session_state.documents_loaded = True
                        st.rerun()

                    except Exception as e:
                        st.error(f"âŒ æŠ“å–å¤±è´¥ï¼š{e}")


def render_file_management(vector_store: "VectorStore") -> None:
    """æ¸²æŸ“æ–‡ä»¶ç®¡ç†é¢æ¿

    Args:
        vector_store: å‘é‡å­˜å‚¨å®ä¾‹
    """
    with st.expander("ğŸ“ æ–‡ä»¶ç®¡ç†"):
        col1, col2 = st.columns(2)

        with col1:
            if st.button("åˆ·æ–°åˆ—è¡¨", use_container_width=True):
                st.rerun()

        with col2:
            files_count = len(vector_store.get_all_sources())
            st.metric("æ–‡ä»¶æ•°é‡", files_count)

        all_sources = vector_store.get_all_sources()
        filenames = [Path(src).name for src in all_sources]

        if filenames:
            selected = st.multiselect(
                "é€‰æ‹©ç”¨äº RAG çš„æ–‡ä»¶",
                options=filenames,
                default=filenames,
                help="å–æ¶ˆé€‰æ‹©å¯ä» RAG ä¸­æ’é™¤"
            )

            # æ›´æ–°é€‰ä¸­çš„æ–‡ä»¶
            filename_to_source = {Path(src).name: src for src in all_sources}
            st.session_state.selected_sources = [
                filename_to_source[name] for name in selected
            ]
        else:
            st.info("æš‚æ— æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£æˆ–æŠ“å–ç½‘é¡µ")
